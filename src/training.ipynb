{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b200e768",
      "metadata": {
        "id": "b200e768",
        "outputId": "dd6eb672-8a6b-4215-b251-50d07dc50495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.5.6-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from keras-tcn) (2.3.1)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
            "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting libclang>=13.0.0 (from tensorflow)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
            "Collecting protobuf>=5.28.0 (from tensorflow)\n",
            "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow)\n",
            "  Downloading termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: typing_extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.14.1)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow)\n",
            "  Downloading wrapt-2.0.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
            "  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting keras>=3.10.0 (from tensorflow)\n",
            "  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting h5py>=3.11.0 (from tensorflow)\n",
            "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.9)\n",
            "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting rich (from keras>=3.10.0->tensorflow)\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting namex (from keras>=3.10.0->tensorflow)\n",
            "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
            "Collecting optree (from keras>=3.10.0->tensorflow)\n",
            "  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading keras_tcn-3.5.6-py3-none-any.whl (12 kB)\n",
            "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
            "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
            "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading wrapt-2.0.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
            "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
            "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow, keras-tcn\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [keras-tcn]26\u001b[0m [tensorflow]-py]\n",
            "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.12.0 keras-tcn-3.5.6 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.33.0 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tcn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(\"/content/cleaned_martian_storms.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "target_col = \"storm_occurrence\"\n",
        "features = [col for col in df.columns if col != target_col]\n",
        "X = df[features].values\n",
        "y = df[target_col].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Create sequences\n",
        "sequence_length = 30\n",
        "num_sequences = len(X_scaled) - sequence_length + 1\n",
        "X_seq = np.zeros((num_sequences, sequence_length, X_scaled.shape[1]))\n",
        "y_seq = np.zeros(num_sequences)\n",
        "\n",
        "for i in range(num_sequences):\n",
        "    X_seq[i] = X_scaled[i:i+sequence_length]\n",
        "    y_seq[i] = y[i+sequence_length-1]\n",
        "\n",
        "# Save as .npz\n",
        "np.savez(\"/content/tcn_ready_dataset.npz\", X=X_seq, y=y_seq)\n",
        "print(\"TCN-ready dataset saved as tcn_ready_dataset.npz\")"
      ],
      "metadata": {
        "id": "da7hRgHtMKQk",
        "outputId": "b5aa216a-d378-4fb9-da1d-794284709acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "da7hRgHtMKQk",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TCN-ready dataset saved as tcn_ready_dataset.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a265752f",
      "metadata": {
        "id": "a265752f",
        "outputId": "01d30af2-7542-4694-f3a7-aaa8e480fab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 | Train Loss: 0.6705 | Val Loss: 0.6228 | Val Acc: 0.7540\n",
            "Precision: 0.7540 | Recall: 1.0000 | F1-score: 0.8597\n",
            "Confusion Matrix:\n",
            "[[  0 170]\n",
            " [  0 521]]\n",
            "Epoch 2/15 | Train Loss: 0.6356 | Val Loss: 0.5993 | Val Acc: 0.7540\n",
            "Precision: 0.7540 | Recall: 1.0000 | F1-score: 0.8597\n",
            "Confusion Matrix:\n",
            "[[  0 170]\n",
            " [  0 521]]\n",
            "Epoch 3/15 | Train Loss: 0.6305 | Val Loss: 0.6343 | Val Acc: 0.7554\n",
            "Precision: 0.7551 | Recall: 1.0000 | F1-score: 0.8604\n",
            "Confusion Matrix:\n",
            "[[  1 169]\n",
            " [  0 521]]\n",
            "Epoch 4/15 | Train Loss: 0.6226 | Val Loss: 0.5859 | Val Acc: 0.7540\n",
            "Precision: 0.7540 | Recall: 1.0000 | F1-score: 0.8597\n",
            "Confusion Matrix:\n",
            "[[  0 170]\n",
            " [  0 521]]\n",
            "Epoch 5/15 | Train Loss: 0.6171 | Val Loss: 0.5860 | Val Acc: 0.7742\n",
            "Precision: 0.7736 | Recall: 0.9904 | F1-score: 0.8687\n",
            "Confusion Matrix:\n",
            "[[ 19 151]\n",
            " [  5 516]]\n",
            "Epoch 6/15 | Train Loss: 0.6034 | Val Loss: 0.5731 | Val Acc: 0.7699\n",
            "Precision: 0.7701 | Recall: 0.9904 | F1-score: 0.8665\n",
            "Confusion Matrix:\n",
            "[[ 16 154]\n",
            " [  5 516]]\n",
            "Epoch 7/15 | Train Loss: 0.6003 | Val Loss: 0.5625 | Val Acc: 0.7757\n",
            "Precision: 0.7773 | Recall: 0.9846 | F1-score: 0.8688\n",
            "Confusion Matrix:\n",
            "[[ 23 147]\n",
            " [  8 513]]\n",
            "Epoch 8/15 | Train Loss: 0.5942 | Val Loss: 0.5602 | Val Acc: 0.7757\n",
            "Precision: 0.7748 | Recall: 0.9904 | F1-score: 0.8694\n",
            "Confusion Matrix:\n",
            "[[ 20 150]\n",
            " [  5 516]]\n",
            "Epoch 9/15 | Train Loss: 0.5871 | Val Loss: 0.5490 | Val Acc: 0.7757\n",
            "Precision: 0.7773 | Recall: 0.9846 | F1-score: 0.8688\n",
            "Confusion Matrix:\n",
            "[[ 23 147]\n",
            " [  8 513]]\n",
            "Epoch 10/15 | Train Loss: 0.5817 | Val Loss: 0.5557 | Val Acc: 0.7742\n",
            "Precision: 0.7736 | Recall: 0.9904 | F1-score: 0.8687\n",
            "Confusion Matrix:\n",
            "[[ 19 151]\n",
            " [  5 516]]\n",
            "Epoch 11/15 | Train Loss: 0.5699 | Val Loss: 0.5378 | Val Acc: 0.7786\n",
            "Precision: 0.7779 | Recall: 0.9885 | F1-score: 0.8707\n",
            "Confusion Matrix:\n",
            "[[ 23 147]\n",
            " [  6 515]]\n",
            "Epoch 12/15 | Train Loss: 0.5637 | Val Loss: 0.5393 | Val Acc: 0.7873\n",
            "Precision: 0.7913 | Recall: 0.9750 | F1-score: 0.8736\n",
            "Confusion Matrix:\n",
            "[[ 36 134]\n",
            " [ 13 508]]\n",
            "Epoch 13/15 | Train Loss: 0.5589 | Val Loss: 0.5552 | Val Acc: 0.7858\n",
            "Precision: 0.8072 | Recall: 0.9405 | F1-score: 0.8688\n",
            "Confusion Matrix:\n",
            "[[ 53 117]\n",
            " [ 31 490]]\n",
            "Epoch 14/15 | Train Loss: 0.5527 | Val Loss: 0.5106 | Val Acc: 0.7873\n",
            "Precision: 0.7877 | Recall: 0.9827 | F1-score: 0.8745\n",
            "Confusion Matrix:\n",
            "[[ 32 138]\n",
            " [  9 512]]\n",
            "Epoch 15/15 | Train Loss: 0.5524 | Val Loss: 0.5178 | Val Acc: 0.7945\n",
            "Precision: 0.7966 | Recall: 0.9770 | F1-score: 0.8776\n",
            "Confusion Matrix:\n",
            "[[ 40 130]\n",
            " [ 12 509]]\n",
            "Training complete. Best model saved as best_tcn_model.pth\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Load TCN-ready dataset\n",
        "# -----------------------------\n",
        "data = np.load(\"/content/tcn_ready_dataset.npz\")\n",
        "X, y = data[\"X\"], data[\"y\"]\n",
        "\n",
        "# Convert to tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Train/Validation Split\n",
        "# -----------------------------\n",
        "train_size = int(0.8 * len(X_tensor))\n",
        "val_size = len(X_tensor) - train_size\n",
        "train_dataset, val_dataset = random_split(TensorDataset(X_tensor, y_tensor), [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Define TCN Model\n",
        "# -----------------------------\n",
        "class TCNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
        "        super(TCNBlock, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                              padding=(kernel_size-1)*dilation, dilation=dilation)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        return self.dropout(self.relu(out))\n",
        "\n",
        "class TCNModel(nn.Module):\n",
        "    def __init__(self, num_features, num_classes=1):\n",
        "        super(TCNModel, self).__init__()\n",
        "        self.tcn1 = TCNBlock(num_features, 64, kernel_size=3, dilation=1)\n",
        "        self.tcn2 = TCNBlock(64, 64, kernel_size=3, dilation=2)\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch, features, seq_len)\n",
        "        x = self.tcn1(x)\n",
        "        x = self.tcn2(x)\n",
        "        x = self.global_pool(x).squeeze(-1)\n",
        "        return self.fc(x)  # raw logits (no sigmoid)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Initialize Model, Loss, Optimizer\n",
        "# -----------------------------\n",
        "model = TCNModel(num_features=X.shape[2])\n",
        "\n",
        "# Handle class imbalance\n",
        "pos_weight = torch.tensor([len(y) / sum(y)])  # ratio of negatives to positives\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Training Loop with Validation & Metrics\n",
        "# -----------------------------\n",
        "epochs = 15\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X).squeeze()\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            outputs = model(batch_X).squeeze()\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            val_loss += loss.item()\n",
        "            preds = (torch.sigmoid(outputs) >= 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    # Metrics\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    val_acc = (np.array(all_preds) == np.array(all_labels)).mean()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
        "          f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"best_tcn_model.pth\")\n",
        "\n",
        "print(\"Training complete. Best model saved as best_tcn_model.pth\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}